from PyQt5 import QtWidgets, QtCore, QtGui
from PyQt5.QtCore import QCoreApplication
from PyQt5.QtCore import Qt
import cv2, os, time,sys
from threading import Thread
import threading
import tempfile
from pathlib import Path
from PyQt5.QtWidgets import QProgressDialog
import numpy as np
import deep_sort.deep_sort.deep_sort as ds
from PyQt5.QtGui import QPixmap,QImage
from PyQt5.QtWidgets import QLabel,QFileDialog
from PIL import Image
# ä¸ç„¶æ¯æ¬¡YOLOå¤„ç†éƒ½ä¼šè¾“å‡ºè°ƒè¯•ä¿¡æ¯
os.environ['YOLO_VERBOSE'] = 'False'
from ultralytics import YOLO 
def putTextWithBackground(img, text, origin, font=cv2.FONT_HERSHEY_SIMPLEX, font_scale=1, text_color=(255, 255, 255), bg_color=(0, 0, 0), thickness=2):
    """ç»˜åˆ¶å¸¦æœ‰èƒŒæ™¯çš„æ–‡æœ¬ã€‚

    :param img: è¾“å…¥å›¾åƒã€‚
    :param text: è¦ç»˜åˆ¶çš„æ–‡æœ¬ã€‚
    :param origin: æ–‡æœ¬çš„å·¦ä¸Šè§’åæ ‡ã€‚
    :param font: å­—ä½“ç±»å‹ã€‚
    :param font_scale: å­—ä½“å¤§å°ã€‚
    :param text_color: æ–‡æœ¬çš„é¢œè‰²ã€‚
    :param bg_color: èƒŒæ™¯çš„é¢œè‰²ã€‚
    :param thickness: æ–‡æœ¬çš„çº¿æ¡åšåº¦ã€‚
    """
    # è®¡ç®—æ–‡æœ¬çš„å°ºå¯¸
    (text_width, text_height), _ = cv2.getTextSize(text, font, font_scale, thickness)

    # ç»˜åˆ¶èƒŒæ™¯çŸ©å½¢
    bottom_left = origin
    top_right = (origin[0] + text_width, origin[1] - text_height - 5)  # å‡å»5ä»¥ç•™å‡ºä¸€äº›è¾¹è·
    cv2.rectangle(img, bottom_left, top_right, bg_color, -1)

    # åœ¨çŸ©å½¢ä¸Šç»˜åˆ¶æ–‡æœ¬
    text_origin = (origin[0], origin[1] - 5)  # ä»å·¦ä¸Šè§’çš„ä½ç½®å‡å»5æ¥ç•™å‡ºä¸€äº›è¾¹è·
    cv2.putText(img, text, text_origin, font, font_scale, text_color, thickness, lineType=cv2.LINE_AA)
    
def extract_detections(results, detect_class):
    """
    ä»æ¨¡å‹ç»“æœä¸­æå–å’Œå¤„ç†æ£€æµ‹ä¿¡æ¯ã€‚
    - results: YoloV8æ¨¡å‹é¢„æµ‹ç»“æœ,åŒ…å«æ£€æµ‹åˆ°çš„ç‰©ä½“çš„ä½ç½®ã€ç±»åˆ«å’Œç½®ä¿¡åº¦ç­‰ä¿¡æ¯ã€‚
    - detect_class: éœ€è¦æå–çš„ç›®æ ‡ç±»åˆ«çš„ç´¢å¼•ã€‚
    å‚è€ƒ: https://docs.ultralytics.com/modes/predict/#working-with-results
    """
    
    # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„äºŒç»´numpyæ•°ç»„ï¼Œç”¨äºå­˜æ”¾æ£€æµ‹åˆ°çš„ç›®æ ‡çš„ä½ç½®ä¿¡æ¯
    # å¦‚æœè§†é¢‘ä¸­æ²¡æœ‰éœ€è¦æå–çš„ç›®æ ‡ç±»åˆ«ï¼Œå¦‚æœä¸åˆå§‹åŒ–ï¼Œä¼šå¯¼è‡´trackeræŠ¥é”™
    detections = np.empty((0, 4)) 
    
    confarray = [] # åˆå§‹åŒ–ä¸€ä¸ªç©ºåˆ—è¡¨ï¼Œç”¨äºå­˜æ”¾æ£€æµ‹åˆ°çš„ç›®æ ‡çš„ç½®ä¿¡åº¦ã€‚
    
    # éå†æ£€æµ‹ç»“æœ
    # å‚è€ƒï¼šhttps://docs.ultralytics.com/modes/predict/#working-with-results
    for r in results:
        for box in r.boxes:
            # å¦‚æœæ£€æµ‹åˆ°çš„ç›®æ ‡ç±»åˆ«ä¸æŒ‡å®šçš„ç›®æ ‡ç±»åˆ«ç›¸åŒ¹é…ï¼Œæå–ç›®æ ‡çš„ä½ç½®ä¿¡æ¯å’Œç½®ä¿¡åº¦
            if box.cls[0].int() == detect_class:
                x1, y1, x2, y2 = box.xywh[0].int().tolist() # æå–ç›®æ ‡çš„ä½ç½®ä¿¡æ¯ï¼Œå¹¶ä»tensorè½¬æ¢ä¸ºæ•´æ•°åˆ—è¡¨ã€‚
                conf = round(box.conf[0].item(), 2) # æå–ç›®æ ‡çš„ç½®ä¿¡åº¦ï¼Œä»tensorä¸­å–å‡ºæµ®ç‚¹æ•°ç»“æœï¼Œå¹¶å››èˆäº”å…¥åˆ°å°æ•°ç‚¹åä¸¤ä½ã€‚
                detections = np.vstack((detections, np.array([x1, y1, x2, y2]))) # å°†ç›®æ ‡çš„ä½ç½®ä¿¡æ¯æ·»åŠ åˆ°detectionsæ•°ç»„ä¸­ã€‚
                confarray.append(conf) # å°†ç›®æ ‡çš„ç½®ä¿¡åº¦æ·»åŠ åˆ°confarrayåˆ—è¡¨ä¸­ã€‚
    return detections, confarray # è¿”å›æå–å‡ºçš„ä½ç½®ä¿¡æ¯å’Œç½®ä¿¡åº¦ã€‚

# è§†é¢‘å¤„ç†
def detect_and_track(input_path: str, output_path: str, detect_class: int, model, tracker) -> Path:
    """
    å¤„ç†è§†é¢‘ï¼Œæ£€æµ‹å¹¶è·Ÿè¸ªç›®æ ‡ã€‚
    - input_path: è¾“å…¥è§†é¢‘æ–‡ä»¶çš„è·¯å¾„ã€‚
    - output_path: å¤„ç†åè§†é¢‘ä¿å­˜çš„è·¯å¾„ã€‚
    - detect_class: éœ€è¦æ£€æµ‹å’Œè·Ÿè¸ªçš„ç›®æ ‡ç±»åˆ«çš„ç´¢å¼•ã€‚
    - model: ç”¨äºç›®æ ‡æ£€æµ‹çš„æ¨¡å‹ã€‚
    - tracker: ç”¨äºç›®æ ‡è·Ÿè¸ªçš„æ¨¡å‹ã€‚
    """
    cap = cv2.VideoCapture(input_path)  # ä½¿ç”¨OpenCVæ‰“å¼€è§†é¢‘æ–‡ä»¶ã€‚
    if not cap.isOpened():  # æ£€æŸ¥è§†é¢‘æ–‡ä»¶æ˜¯å¦æˆåŠŸæ‰“å¼€ã€‚
        print(f"Error opening video file {input_path}")
        return None
    
    fps = cap.get(cv2.CAP_PROP_FPS)  # è·å–è§†é¢‘çš„å¸§ç‡
    size = (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))) # è·å–è§†é¢‘çš„åˆ†è¾¨ç‡ï¼ˆå®½åº¦å’Œé«˜åº¦ï¼‰ã€‚
    output_video_path = Path(output_path) / "output.avi" # è®¾ç½®è¾“å‡ºè§†é¢‘çš„ä¿å­˜è·¯å¾„ã€‚

    # è®¾ç½®è§†é¢‘ç¼–ç æ ¼å¼ä¸ºXVIDæ ¼å¼çš„aviæ–‡ä»¶
    # å¦‚æœéœ€è¦ä½¿ç”¨h264ç¼–ç æˆ–è€…éœ€è¦ä¿å­˜ä¸ºå…¶ä»–æ ¼å¼ï¼Œå¯èƒ½éœ€è¦ä¸‹è½½openh264-1.8.0
    # ä¸‹è½½åœ°å€ï¼šhttps://github.com/cisco/openh264/releases/tag/v1.8.0
    # ä¸‹è½½å®Œæˆåå°†dllæ–‡ä»¶æ”¾åœ¨å½“å‰æ–‡ä»¶å¤¹å†…
    fourcc = cv2.VideoWriter_fourcc(*"XVID")
    output_video = cv2.VideoWriter(output_video_path.as_posix(), fourcc, fps, size, isColor=True) # åˆ›å»ºä¸€ä¸ªVideoWriterå¯¹è±¡ç”¨äºå†™è§†é¢‘ã€‚

    # å¯¹æ¯ä¸€å¸§å›¾ç‰‡è¿›è¡Œè¯»å–å’Œå¤„ç†
    while True:
        success, frame = cap.read() # é€å¸§è¯»å–è§†é¢‘ã€‚
        
        # å¦‚æœè¯»å–å¤±è´¥ï¼ˆæˆ–è€…è§†é¢‘å·²å¤„ç†å®Œæ¯•ï¼‰ï¼Œåˆ™è·³å‡ºå¾ªç¯ã€‚
        if not (success):
            break

        # ä½¿ç”¨YoloV8æ¨¡å‹å¯¹å½“å‰å¸§è¿›è¡Œç›®æ ‡æ£€æµ‹ã€‚
        results = model(frame, stream=True)

        # ä»é¢„æµ‹ç»“æœä¸­æå–æ£€æµ‹ä¿¡æ¯ã€‚
        detections, confarray = extract_detections(results, detect_class)

        # ä½¿ç”¨deepsortæ¨¡å‹å¯¹æ£€æµ‹åˆ°çš„ç›®æ ‡è¿›è¡Œè·Ÿè¸ªã€‚
        resultsTracker = tracker.update(detections, confarray, frame)
        
        for x1, y1, x2, y2, Id in resultsTracker:
            x1, y1, x2, y2 = map(int, [x1, y1, x2, y2]) # å°†ä½ç½®ä¿¡æ¯è½¬æ¢ä¸ºæ•´æ•°ã€‚

            # ç»˜åˆ¶bounding boxå’Œæ–‡æœ¬
            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 3)
            putTextWithBackground(frame, str(int(Id)), (max(-10, x1), max(40, y1)), font_scale=1.5, text_color=(255, 255, 255), bg_color=(255, 0, 255))

        output_video.write(frame)  # å°†å¤„ç†åçš„å¸§å†™å…¥åˆ°è¾“å‡ºè§†é¢‘æ–‡ä»¶ä¸­ã€‚
            
    output_video.release()  # é‡Šæ”¾VideoWriterå¯¹è±¡ã€‚
    cap.release()  # é‡Šæ”¾è§†é¢‘æ–‡ä»¶ã€‚
    
    print(f'output dir is: {output_video_path}')
    return output_video_path
class MWindow(QtWidgets.QMainWindow):

    def __init__(self):
        super().__init__()
        self.setupUI()
        self.videoBtn.clicked.connect(self.choose_video)
        self.startBtn.clicked.connect(self.play_video)
        self.stopBtn.clicked.connect(self.stop_video)
        self.pauseBtn.clicked.connect(self.pause_video)
        self.isPlaying = False  # æ§åˆ¶è§†é¢‘æ’­æ”¾çš„çŠ¶æ€

        # åœ¨å¼€å§‹æ—¶è¾“å‡ºæ—¥å¿—ä¿¡æ¯
        self.textLog.append("åŸºäºæ·±åº¦å­¦ä¹ çš„å»ºç­‘å·¥äººè§†é¢‘è·Ÿè¸ªæŠ€æœ¯")

        # åˆå§‹åŒ–æ—¶åŠ è½½é»˜è®¤å›¾ç‰‡
        self.load_default_image()
    def load_default_image(self):
        self.default_img = QPixmap('R-C.jpg')
        self.set_default_image()
    def pause_video(self):
        # åˆ‡æ¢æ’­æ”¾çŠ¶æ€
        self.isPlaying = not self.isPlaying
        if self.isPlaying:
            self.pauseBtn.setText('â¸ï¸æš‚åœæ’­æ”¾')
            self.textLog.append("è§†é¢‘æ’­æ”¾å·²ç»§ç»­")
        else:
            self.pauseBtn.setText('â–¶ç»§ç»­æ’­æ”¾')
            self.textLog.append("è§†é¢‘æ’­æ”¾å·²æš‚åœ")

    def set_default_image(self):
        scaled_img = self.default_img.scaled(640, 360, Qt.IgnoreAspectRatio, Qt.SmoothTransformation)
        self.label_ori_video.setPixmap(scaled_img)
        self.label_process_video.setPixmap(scaled_img)
    def setupUI(self):
        self.resize(1200, 800)
        self.setWindowTitle('åŸºäºæ·±åº¦å­¦ä¹ çš„å»ºç­‘å·¥äººè§†é¢‘è·Ÿè¸ªæŠ€æœ¯')  # è®¾ç½®çª—å£çš„æ ‡é¢˜



        
        # è®¾ç½®å…¨å±€èƒŒæ™¯é¢œè‰²ï¼Œä½†æ’é™¤äº†ç‰¹å®šçš„ç»„ä»¶
        self.setStyleSheet("QMainWindow { font-size: 16pt; background-color: #FF7F50; }"
                           "QPushButton { background-color: none; }"  # ä¿æŒæŒ‰é’®é»˜è®¤èƒŒæ™¯
                           "QLabel { background-color: none; }")  # ä¿æŒå…¶ä»–æ ‡ç­¾é»˜è®¤èƒŒæ™¯

        centralWidget = QtWidgets.QWidget(self)
        self.setCentralWidget(centralWidget)
        mainLayout = QtWidgets.QVBoxLayout(centralWidget)
        topLayout = QtWidgets.QHBoxLayout()
         # åˆ›å»ºå¹¶è®¾ç½®æ ‡é¢˜æ ‡ç­¾
        titleLabel = QtWidgets.QLabel("åŸºäºæ·±åº¦å­¦ä¹ çš„å»ºç­‘å·¥äººè§†é¢‘è·Ÿè¸ªæŠ€æœ¯")
        titleLabel.setAlignment(Qt.AlignCenter)  # æ ‡é¢˜å±…ä¸­
        titleLabel.setStyleSheet("font-size: 24pt; font-weight: bold;")  # è®¾ç½®å­—ä½“å¤§å°å’ŒåŠ ç²—
        mainLayout.addWidget(titleLabel)  # å°†æ ‡é¢˜æ ‡ç­¾æ·»åŠ åˆ°å¸ƒå±€ä¸­
        videoLabelLayout1 = QtWidgets.QVBoxLayout()
        self.label_ori_video = QtWidgets.QLabel(self)
        self.label_ori_video.setMinimumSize(640, 360)
        # ä¸ºlabel_ori_videoè®¾ç½®ç‰¹å®šçš„èƒŒæ™¯é¢œè‰²
        self.label_ori_video.setStyleSheet('border: 1px solid #D7E2F9; background-color: #FDF5E6;')  # ç¡®ä¿æ­¤æ ‡ç­¾æœ‰ç™½è‰²èƒŒæ™¯
        label_ori_video_title = QtWidgets.QLabel("è¿½è¸ªåŸè§†é¢‘")
        label_ori_video_title.setAlignment(Qt.AlignCenter)
        label_ori_video_title.setStyleSheet("font-size: 14pt; font-weight: bold;")
        videoLabelLayout1.addWidget(self.label_ori_video)
        videoLabelLayout1.addWidget(label_ori_video_title)
        topLayout.addLayout(videoLabelLayout1)

        videoLabelLayout2 = QtWidgets.QVBoxLayout()
        self.label_process_video = QtWidgets.QLabel(self)
        self.label_process_video.setMinimumSize(640, 360)
        self.label_process_video.setStyleSheet('border: 1px solid #D7E2F9;background-color: #FDF5E6;')  # ç»´æŒæ­¤æ ‡ç­¾ç‰¹å®šæ ·å¼
        label_process_video_title = QtWidgets.QLabel("è¿½è¸ªåè§†é¢‘")
        label_process_video_title.setAlignment(Qt.AlignCenter)
        label_process_video_title.setStyleSheet("font-size: 14pt; font-weight: bold;")
        videoLabelLayout2.addWidget(self.label_process_video)
        videoLabelLayout2.addWidget(label_process_video_title)
        topLayout.addLayout(videoLabelLayout2)
        
        mainLayout.addLayout(topLayout)

        groupBox = QtWidgets.QGroupBox(self)
        bottomLayout = QtWidgets.QHBoxLayout(groupBox)
        self.textLog = QtWidgets.QTextBrowser()
        self.textLog.setStyleSheet("font-size: 18pt;background-color:#F5DEB3")  # æ–‡æœ¬æ¡†ä¿æŒç‰¹å®šæ ·å¼
        bottomLayout.addWidget(self.textLog, 1)

        mainLayout.addWidget(groupBox)

        btnLayout = QtWidgets.QVBoxLayout()
        self.videoBtn = QtWidgets.QPushButton('ğŸï¸é€‰æ‹©è§†é¢‘æ–‡ä»¶')
        self.startBtn = QtWidgets.QPushButton('â–¶å¼€å§‹æ’­æ”¾')
        self.stopBtn = QtWidgets.QPushButton('â¹ï¸åœæ­¢æ’­æ”¾')
        btnStyle = "QPushButton { font-size: 18pt; }"
        self.pauseBtn = QtWidgets.QPushButton('â¸ï¸æš‚åœæ’­æ”¾')
        self.pauseBtn.setStyleSheet(btnStyle)
        self.videoBtn.setStyleSheet(btnStyle)
        self.startBtn.setStyleSheet(btnStyle)
        self.stopBtn.setStyleSheet(btnStyle)
        btnLayout.addWidget(self.videoBtn)
        btnLayout.addWidget(self.startBtn)
        btnLayout.addWidget(self.pauseBtn)
        btnLayout.addWidget(self.stopBtn)
        bottomLayout.addLayout(btnLayout, 0)


    # def play_video(self):
    #     cap = cv2.VideoCapture('output\output.avi')
    #     if not cap.isOpened():
    #         self.textLog.append("Error: Unable to open video.")
    #         return

    #     while True:
    #         ret, frame = cap.read()
    #         if not ret:
    #             break

    #         # å°†OpenCVçš„å›¾åƒæ ¼å¼è½¬æ¢ä¸ºQtæ”¯æŒçš„æ ¼å¼
    #         height, width, channel = frame.shape
    #         bytesPerLine = 3 * width
    #         qImg = QImage(frame.data, width, height, bytesPerLine, QImage.Format_RGB888).rgbSwapped()
    #         pixmap = QPixmap.fromImage(qImg)

    #         # åœ¨æ ‡ç­¾ä¸­æ˜¾ç¤ºè§†é¢‘å¸§
    #         self.label_ori_video.setPixmap(pixmap.scaled(self.label_ori_video.size(), Qt.KeepAspectRatio))

    #         # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ï¼Œä»¥ä¾¿å¯ä»¥è§‚å¯Ÿè§†é¢‘å¸§
    #         cv2.waitKey(30)

    #     cap.release()
    def play_video(self):
        self.isPlaying = True
        frame_count = 0
        self.cap1 = cv2.VideoCapture('output/output.avi')
        self.cap2 = cv2.VideoCapture(self.video_file_path)
        if not self.cap1.isOpened() or not self.cap2.isOpened():
            self.textLog.append("Error: Unable to open video.")
            return

        while True:  # ä¸»å¾ªç¯
            if self.isPlaying:
                ret1, frame1 = self.cap1.read()
                ret2, frame2 = self.cap2.read()
                if not ret1 or not ret2:
                    break
                putTextWithBackground(frame1, f"Frame: {frame_count}", (10, 50), font_scale=2)
                putTextWithBackground(frame2, f"Frame: {frame_count}", (10, 50), font_scale=2)
                frame_count += 1
                self.update_video_display(frame1, self.label_process_video)
                self.update_video_display(frame2, self.label_ori_video)
                cv2.waitKey(30)
            else:
                cv2.waitKey(500)  # çŸ­æš‚ç­‰å¾…ï¼Œå‡å°‘CPUä½¿ç”¨ç‡

        self.cap1.release()
        self.cap2.release()
        self.set_default_image()

    def update_video_display(self, frame, label):
        if frame is not None:
            height, width, channel = frame.shape
            bytesPerLine = 3 * width
            qImg = QImage(frame.data, width, height, bytesPerLine, QImage.Format_RGB888).rgbSwapped()
            pixmap = QPixmap.fromImage(qImg)
            label.setPixmap(pixmap.scaled(label.size(), Qt.KeepAspectRatio))
    # def play_video(self):
    #     self.isPlaying = True  # å¼€å§‹æ’­æ”¾è§†é¢‘æ—¶è®¾ç½®ä¸ºTrue
    #     # æ‰“å¼€è§†é¢‘
    #     self.cap1 = cv2.VideoCapture('output/output.avi')
    #     self.cap2 = cv2.VideoCapture(self.video_file_path)
    #     if not self.cap1.isOpened() or not self.cap2.isOpened():
    #         self.textLog.append("Error: Unable to open video.")
    #         return

    #     while self.isPlaying:  # ä½¿ç”¨ isPlaying æ§åˆ¶æ’­æ”¾å¾ªç¯
    #         ret1, frame1 = self.cap1.read()
    #         ret2, frame2 = self.cap2.read()
    #         if not ret1 or not ret2:
    #             break

    #         # æ›´æ–°UIä¸­çš„è§†é¢‘æ˜¾ç¤º
    #         self.update_video_display(frame1, self.label_process_video)
    #         self.update_video_display(frame2, self.label_ori_video)

    #         cv2.waitKey(30)

    #     self.cap1.release()
    #     self.cap2.release()
    #     self.set_default_image()

    # def choose_video(self):
    #     # æ‰“å¼€æ–‡ä»¶å¯¹è¯æ¡†
    #     options = QFileDialog.Options()
    #     file_path, _ = QFileDialog.getOpenFileName(self, "é€‰æ‹©è§†é¢‘æ–‡ä»¶", "", "è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi)", options=options)
    #     if file_path:
    #         # å¦‚æœç”¨æˆ·é€‰æ‹©äº†æ–‡ä»¶ï¼Œå°†æ–‡ä»¶è·¯å¾„æ˜¾ç¤ºåœ¨è¾“å‡ºæ¡†ä¸­
    #         self.textLog.append(f"é€‰æ‹©çš„è§†é¢‘æ–‡ä»¶ï¼š{file_path}")
    #         self.video_file_path = file_path  # å°†æ–‡ä»¶è·¯å¾„ä¿å­˜åœ¨å®ä¾‹å˜é‡ä¸­
    #         detect_and_track(self.video_file_path, output_path, detect_class, model, tracker)
    #         self.textLog.append("è§†é¢‘å¤„ç†å®Œæˆ")
    def choose_video(self):
        # æ‰“å¼€æ–‡ä»¶å¯¹è¯æ¡†
        options = QFileDialog.Options()
        file_path, _ = QFileDialog.getOpenFileName(self, "é€‰æ‹©è§†é¢‘æ–‡ä»¶", "", "è§†é¢‘æ–‡ä»¶ (*.mp4 *.avi)", options=options)
        if file_path:
            # å¦‚æœç”¨æˆ·é€‰æ‹©äº†æ–‡ä»¶ï¼Œå°†æ–‡ä»¶è·¯å¾„æ˜¾ç¤ºåœ¨è¾“å‡ºæ¡†ä¸­
            self.textLog.append(f"å·²é€‰æ‹©çš„è§†é¢‘æ–‡ä»¶ï¼š{file_path}")
            self.video_file_path = file_path  # å°†æ–‡ä»¶è·¯å¾„ä¿å­˜åœ¨å®ä¾‹å˜é‡ä¸­
            # åˆ›å»ºçº¿ç¨‹æ¥æ‰§è¡Œ detect_and_track å‡½æ•°
            thread = threading.Thread(target=self.execute_detect_and_track)
            thread.start()

    def execute_detect_and_track(self):
        # æ‰§è¡Œ detect_and_track å‡½æ•°
        detect_and_track(self.video_file_path, output_path, detect_class, model, tracker)
        # å¤„ç†å®Œæˆåå‘self.textLogæ·»åŠ æ—¥å¿—
        self.textLog.append("ç¨‹åºé¢„å¤„ç†å®Œæˆ")

    def stop_video(self):
        # è®¾ç½®ä¸ºFalseä»¥åœæ­¢è§†é¢‘æ’­æ”¾
        self.isPlaying = False  
        # å…³é—­è§†é¢‘æ–‡ä»¶
        if hasattr(self, 'cap1') and self.cap1.isOpened():
            self.cap1.release()
        if hasattr(self, 'cap2') and self.cap2.isOpened():
            self.cap2.release()
        # é‡æ–°åŠ è½½é»˜è®¤å›¾ç‰‡
        self.load_default_image()  
        # æ›´æ–°æ—¥å¿—ä¿¡æ¯
        self.textLog.append("è§†é¢‘æ’­æ”¾å·²åœæ­¢")

    def append_log(self, message):
        # åœ¨ä¸»çº¿ç¨‹ä¸­å®‰å…¨åœ°æ›´æ–°æ—¥å¿—
        self.textLog.append(message)
        QCoreApplication.processEvents()
    def update_video_display(self, frame, label):
        if frame is not None:
            height, width, channel = frame.shape
            bytesPerLine = 3 * width
            qImg = QImage(frame.data, width, height, bytesPerLine, QImage.Format_RGB888).rgbSwapped()
            pixmap = QPixmap.fromImage(qImg)
            label.setPixmap(pixmap.scaled(label.size(), Qt.KeepAspectRatio))

if __name__ == "__main__":
        # æŒ‡å®šè¾“å…¥è§†é¢‘çš„è·¯å¾„ã€‚
    ######
    input_path = "test.mp4"
    ######

    # è¾“å‡ºæ–‡ä»¶å¤¹ï¼Œé»˜è®¤ä¸ºç³»ç»Ÿçš„ä¸´æ—¶æ–‡ä»¶å¤¹è·¯å¾„
    output_path = 'output'  # åˆ›å»ºä¸€ä¸ªä¸´æ—¶ç›®å½•ç”¨äºå­˜æ”¾è¾“å‡ºè§†é¢‘ã€‚

    # åŠ è½½yoloV8æ¨¡å‹æƒé‡
    model = YOLO("yolov8n.pt")

    # è®¾ç½®éœ€è¦æ£€æµ‹å’Œè·Ÿè¸ªçš„ç›®æ ‡ç±»åˆ«
    detect_class = 0
    # print(f"detecting {model.names[detect_class]}") # model.namesè¿”å›æ¨¡å‹æ‰€æ”¯æŒçš„æ‰€æœ‰ç‰©ä½“ç±»åˆ«

    # åŠ è½½DeepSortæ¨¡å‹
    tracker = ds.DeepSort("deep_sort/deep_sort/deep/checkpoint/ckpt.t7")

    app = QtWidgets.QApplication([])
    window = MWindow()
    window.show()
    sys.exit(app.exec())